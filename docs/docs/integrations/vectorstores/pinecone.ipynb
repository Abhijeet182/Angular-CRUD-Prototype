{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhijeet182/Angular-CRUD-Prototype/blob/master/docs/docs/integrations/vectorstores/pinecone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "683953b3",
      "metadata": {
        "id": "683953b3"
      },
      "source": [
        "# Pinecone\n",
        "\n",
        ">[Pinecone](https://docs.pinecone.io/docs/overview) is a vector database with broad functionality.\n",
        "\n",
        "This notebook shows how to use functionality related to the `Pinecone` vector database.\n",
        "\n",
        "## Setup\n",
        "\n",
        "To use the `PineconeVectorStore` you first need to install the partner package, as well as the other packages used throughout this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b4c41cad-08ef-4f72-a545-2151e4598efe",
      "metadata": {
        "tags": [],
        "id": "b4c41cad-08ef-4f72-a545-2151e4598efe",
        "outputId": "ce4306c2-e1fd-4a64-cc65-f20ca731e84b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: pinecone 6.0.2 does not provide the extra 'async'\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.9/62.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.9/421.9 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install -qU langchain langchain-pinecone langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1917d123",
      "metadata": {
        "id": "1917d123"
      },
      "source": [
        "Migration note: if you are migrating from the `langchain_community.vectorstores` implementation of Pinecone, you may need to remove your `pinecone-client` v2 dependency before installing `langchain-pinecone`, which relies on `pinecone-client` v6."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef6dc4de",
      "metadata": {
        "id": "ef6dc4de"
      },
      "source": [
        "### Credentials\n",
        "\n",
        "Create a new Pinecone account, or sign into your existing one, and create an API key to use in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "eb554814",
      "metadata": {
        "id": "eb554814",
        "outputId": "3fc21c89-5128-41e5-d4f5-9f5315c77a36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b1797ec3-e83d-4ff7-b573-c0df24e03c83··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "from pinecone import Pinecone\n",
        "\n",
        "if not os.getenv(\"PINECONE_API_KEY\"):\n",
        "    os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"b1797ec3-e83d-4ff7-b573-c0df24e03c83\")\n",
        "\n",
        "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
        "\n",
        "pc = Pinecone(api_key=pinecone_api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ef1d828",
      "metadata": {
        "id": "6ef1d828"
      },
      "source": [
        "If you want to get automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "23b5ac5e",
      "metadata": {
        "id": "23b5ac5e"
      },
      "outputs": [],
      "source": [
        " os.environ[\"AZURE_OPENAI_API_KEY\"] = \"ce34b668bbaf448e9698586bcb4e83c9\"\n",
        " os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\"] = \"text-embedding-3-small\"\n",
        " os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://prasu-m2348dzf-eastus.cognitiveservices.azure.com/\"\n",
        " os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-12-01-preview\"\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "658706a3",
      "metadata": {
        "id": "658706a3"
      },
      "source": [
        "## Initialization\n",
        "\n",
        "Before initializing our vector store, let's connect to a Pinecone index. If one named `index_name` doesn't exist, it will be created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "276a06dd",
      "metadata": {
        "id": "276a06dd"
      },
      "outputs": [],
      "source": [
        "from pinecone import ServerlessSpec\n",
        "\n",
        "index_name = \"google-collab\"  # change if desired\n",
        "\n",
        "if not pc.has_index(index_name):\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=1536,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        "    )\n",
        "\n",
        "index = pc.Index(index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "1485db56",
      "metadata": {
        "id": "1485db56"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "\n",
        "embeddings = AzureOpenAIEmbeddings(\n",
        "    azure_deployment=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "6e104aee",
      "metadata": {
        "id": "6e104aee",
        "outputId": "bea57f4d-29af-4c2a-ba7f-7cbedc58cfb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x7d80c2d94d50>\n"
          ]
        }
      ],
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "vector_store = PineconeVectorStore(index=index, embedding=embeddings)\n",
        "print(vector_store)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48721e29",
      "metadata": {
        "id": "48721e29"
      },
      "source": [
        "## Manage vector store\n",
        "\n",
        "Once you have created your vector store, we can interact with it by adding and deleting different items.\n",
        "\n",
        "### Add items to vector store\n",
        "\n",
        "We can add items to our vector store by using the `add_documents` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "70e688f4",
      "metadata": {
        "id": "70e688f4",
        "outputId": "e33bc1bb-e9ac-4ce3-adba-50f3fd5e582a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'embedding' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-03ce56f5da41>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m ]\n\u001b[1;32m     67\u001b[0m \u001b[0muuids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muuid4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mvector_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muuids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_store\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'embedding' is not defined"
          ]
        }
      ],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_2 = Document(\n",
        "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_3 = Document(\n",
        "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_4 = Document(\n",
        "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_5 = Document(\n",
        "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_6 = Document(\n",
        "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_7 = Document(\n",
        "    page_content=\"The top 10 soccer players in the world right now.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_8 = Document(\n",
        "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_9 = Document(\n",
        "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_10 = Document(\n",
        "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "documents = [\n",
        "    document_1,\n",
        "    document_2,\n",
        "    document_3,\n",
        "    document_4,\n",
        "    document_5,\n",
        "    document_6,\n",
        "    document_7,\n",
        "    document_8,\n",
        "    document_9,\n",
        "    document_10,\n",
        "]\n",
        "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
        "vector_store.from_documents(embedding=embedding, ids=uuids)\n",
        "print(vector_store)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "120922b3",
      "metadata": {
        "id": "120922b3"
      },
      "source": [
        "### Delete items from vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "5b8437cd",
      "metadata": {
        "id": "5b8437cd"
      },
      "outputs": [],
      "source": [
        "vector_store.delete(ids=[uuids[-1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ee21c89",
      "metadata": {
        "id": "5ee21c89"
      },
      "source": [
        "## Query vector store\n",
        "\n",
        "Once your vector store has been created and the relevant documents have been added you will most likely wish to query it during the running of your chain or agent.\n",
        "\n",
        "### Query directly\n",
        "\n",
        "Performing a simple similarity search can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "ffbcb3fb",
      "metadata": {
        "id": "ffbcb3fb",
        "outputId": "8f628dcd-c638-4d57-9ea7-2664ac3662ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n",
            "* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n"
          ]
        }
      ],
      "source": [
        "results = vector_store.similarity_search(\n",
        "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
        "    k=2,\n",
        "    filter={\"source\": \"tweet\"},\n",
        ")\n",
        "for res in results:\n",
        "    print(f\"* {res.page_content} [{res.metadata}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79f3494d",
      "metadata": {
        "id": "79f3494d"
      },
      "source": [
        "#### Similarity search with score\n",
        "\n",
        "You can also search with score:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "5fb24583",
      "metadata": {
        "id": "5fb24583",
        "outputId": "7b839141-742f-40ac-bf3e-1111d26e0143",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* [SIM=0.569517] The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees. [{'source': 'news'}]\n"
          ]
        }
      ],
      "source": [
        "results = vector_store.similarity_search_with_score(\n",
        "    \"Will it be hot tomorrow?\", k=1, filter={\"source\": \"news\"}\n",
        ")\n",
        "for res, score in results:\n",
        "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1855941b",
      "metadata": {
        "id": "1855941b"
      },
      "source": [
        "#### Other search methods\n",
        "\n",
        "There are more search methods (such as MMR) not listed in this notebook, to find all of them be sure to read the [API reference](https://python.langchain.com/api_reference/pinecone/vectorstores/langchain_pinecone.vectorstores.PineconeVectorStore.html).\n",
        "\n",
        "### Query by turning into retriever\n",
        "\n",
        "You can also transform the vector store into a retriever for easier usage in your chains."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "78140e87",
      "metadata": {
        "id": "78140e87",
        "outputId": "be2fa50d-182f-42f6-9220-36b35d981d4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='f447ff1e-7423-4632-8a67-48308d911436', metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.')]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "retriever = vector_store.as_retriever(\n",
        "    search_type=\"similarity_score_threshold\",\n",
        "    search_kwargs={\"k\": 1, \"score_threshold\": 0.4},\n",
        ")\n",
        "retriever.invoke(\"Stealing from the bank is a crime\", filter={\"source\": \"news\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72990cb5",
      "metadata": {
        "id": "72990cb5"
      },
      "source": [
        "## Usage for retrieval-augmented generation\n",
        "\n",
        "For guides on how to use this vector store for retrieval-augmented generation (RAG), see the following sections:\n",
        "\n",
        "- [Tutorials](/docs/tutorials/)\n",
        "- [How-to: Question and answer with RAG](https://python.langchain.com/docs/how_to/#qa-with-rag)\n",
        "- [Retrieval conceptual docs](https://python.langchain.com/docs/concepts/retrieval)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d5722bc",
      "metadata": {
        "id": "0d5722bc"
      },
      "source": [
        "## API reference\n",
        "\n",
        "For detailed documentation of all features and configurations head to the API reference: https://python.langchain.com/api_reference/pinecone/vectorstores/langchain_pinecone.vectorstores.PineconeVectorStore.html"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}